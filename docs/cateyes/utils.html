<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.0" />
<title>cateyes.utils API documentation</title>
<meta name="description" content="cateyes.utils provides utility functions to convert and handle data." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>cateyes.utils</code></h1>
</header>
<section id="section-intro">
<p>cateyes.utils provides utility functions to convert and handle data.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># -*- coding: utf-8 -*-
# (c) Dirk GÃ¼tlin, 2021. &lt;dirk.guetlin@gmail.com&gt;
#
# License: BSD-3-Clause

&#34;&#34;&#34;
cateyes.utils provides utility functions to convert and handle data.
&#34;&#34;&#34;

import numpy as np
import warnings

WARN_SFREQ = &#34;\n\nIrregular sampling rate detected. This can lead to impaired &#34; \
            &#34;performance with this classifier. Consider resampling your data to &#34; \
            &#34;a fixed sampling rate. Setting sampling rate to average sample difference.&#34;

WARN_CONT = &#34;\n\nThe discrete_times array passed to continuous_to_discrete &#34; \
            &#34;has the same length as the times array. Are you sure that your &#34; \
            &#34;discrete_times and discrete_values are not already continuous? &#34; \
            &#34;If they are, applying this function can lead to miscalculations.&#34; 

def sample_data_path(name):
    &#34;&#34;&#34;return the static path to a CatEyes sample dataset.
    
    Parameters
    ----------
    name : str
        The example file to load. Possible names are: &#39;example_data&#39;,
        &#39;example_events&#39; and &#39;test_data_full&#39;.
   
    Returns
    -------
    data_path : str
        The absolute path leading to the respective .csv file on your 
        machine.
        &#34;&#34;&#34;
    import os.path as op
    data_dir = op.join(op.dirname(__file__), &#34;data&#34;)
    data_path = op.join(data_dir, name + &#34;.csv&#34;)
    return op.abspath(data_path)


def discrete_to_continuous(times, discrete_times, discrete_values):
    &#34;&#34;&#34;Matches an array of discrete events to a continuous time series.
    
    Parameters
    ----------
    times : array of (float, int)
        A 1D-array representing the sampling times of the continuous 
        eyetracking recording.
    discrete_times : array of (float, int)
        A 1D-array representing discrete timepoints at which a specific
        event occurs. Is used to map `discrete_values` onto `times`.
    discrete_values : array
        A 1D-array containing the event description or values 
        corresponding to `discrete_times`. Must be the same length as 
        `discrete_times`.
        
    Returns
    -------
    indices : array of int
        Array of length len(times) corresponding to the event index 
        of the discrete events mapped onto the sampling times.
    values : array
        Array of length len(times) corresponding to the event values
        or descriptions of the discrete events.
        
    Example
    --------
    &gt;&gt;&gt; times = np.array([0., 0.1, 0.2])
    &gt;&gt;&gt; dis_times, dis_values = [0.1], [&#34;Saccade&#34;]
    &gt;&gt;&gt; discrete_to_continuous(times, dis_times, dis_values)
    array([0., 1., 1.]), array([None, &#39;Saccade&#39;, &#39;Saccade&#39;])
    &#34;&#34;&#34;
    # check to prevent passing continuous array
    if len(discrete_times) == len(times):
        warnings.warn(WARN_CONT)
    #TODO: Items will be dropped if 2 discrete events fall on one sample.
    # how to deal with this?
    
    # sort the discrete events by time
    time_val_sorted = sorted(zip(discrete_times, discrete_values),
                            key= lambda x:x[0])
    
    # fill the time series with indices and values
    indices = np.zeros(len(times))
    shape, dtype = [(x.shape, x.dtype) for x in [np.array(discrete_values)]][0]
    values = np.full((len(times),) + shape[1:], None).astype(dtype)
    for idx, (dis_time, dis_val) in enumerate(time_val_sorted):
        selected = times &gt;= dis_time
        indices[selected] = idx + 1
        values[selected] = dis_val
        #for i in np.where(selected)[0]:  # this allows multidim arrays to pass
        #    values[i] = dis_val
        
    return indices, values


def continuous_to_discrete(times, indices, values):
    &#34;&#34;&#34;Matches an array of discrete events to a continuous time series.
    Reverse function of `discrete_to_continuous`.
    
    Parameters
    ----------
    times : array of (float, int)
        A 1D-array representing the sampling times of the continuous 
        eyetracking recording.
    indices : array of int
        Array of length len(times) corresponding to the event index 
        of the discrete events mapped onto the sampling times.
    values : array
        Array of length len(times) corresponding to the event values
        or descriptions of the discrete events.
   
    Returns
    -------
    discrete_times : array of (float, int)
        A 1D-array representing discrete timepoints at which a specific
        event occurs.
    discrete_values : array
        A 1D-array containing the event description or values 
        corresponding to `discrete_times`. Is the same length as 
        `discrete_times`.
    &#34;&#34;&#34;
    # check to prevent passing discrete array
    if any([len(times) != i for i in (len(indices), len(values))]):
        raise ValueError(&#34;Indices and values must have the &#34; \
                         &#34;same length as the times array.&#34;)
    
    # fill the discrete lists with events
    discrete_times = []
    discrete_values = []
    cur_idx = np.min(indices) - 1
    for time, idx, val in zip(times, indices, values):
        if idx &gt; cur_idx:
            discrete_times.append(time)
            discrete_values.append(val)
        cur_idx = idx
    
    return discrete_times, discrete_values


def get_segment_distance(x, y, times, segments, from_discrete=False,
                        return_start_end_pos=False):
    &#34;&#34;&#34;Calculate the movement distance from start to end of a segment.
    This function can be used to calculate Saccade distance.
    
    Parameters
    ----------
    x : array of float
        A 1D-array representing the x-axis of your gaze data.
    y : array of float
        A 1D-array representing the y-axis of your gaze data.
    times : array of (float, int)
        A 1D-array representing the sampling times of the continuous 
        eyetracking recording.
    segments : array of (int, float)
        Either the event indices (continuous format) or the event 
        times (discrete format), indicating the start of a new segment.
    from_discrete : bool
        If True, assumes that `segments` is a discrete array and will
        also return a discrete array. Else, will treat `segments` as
        continuous array and return a continuous array. Default=False.
    return_start_end_pos : bool
        If True, additionally return the initial and final position of
        the gaze array during each segment. Default=False.
        
        
    Returns
    -------
    distances : array of float
        Array of length len(times) corresponding to the distance
        between the first and the last sample in a segment.
    start_pos : array of float
        A 2D array of shape [n_events, 2] (discrete) or 
        [n_samples, 2] (continuous) containing the initial gaze 
        positions for each segment. The second dimension of the 
        array corresponds to the x and y axis (in that order).
        Only returned if `return_start_end_pos=True`.
    end_pos : array of float
        A 2D array of shape [n_events, 2] (discrete) or 
        [n_samples, 2] (continuous) containing the final gaze 
        positions for each segment. The second dimension of the 
        array corresponds to the x and y axis (in that order).
        Only returned if `return_start_end_pos=True`.
    &#34;&#34;&#34;
    # check if continuous segments match length
    msg = &#34;For continuous segments, len(segments) must be equal to &#34; \
    &#34;len(times). If you are using a discrete segment array, please &#34; \
    &#34;pass `discrete=True` as an argument&#34;
    if not from_discrete:
        if len(segments) != len(times):
            raise ValueError(msg)

        # make discrete if continuous
        segments, _ = continuous_to_discrete(times, segments, x)

    # sort the discrete events by time
    seg_times = sorted(segments)
    
    # loop over segments to find start and end positions
    start_pos, end_pos = np.zeros([2, len(seg_times), 2])  # 2 2D arrays
    nxt_seg_times = np.concatenate([seg_times[1:], [np.inf]])
    for idx, (cur, nxt) in enumerate(zip(seg_times, nxt_seg_times)):

        # select the segment in question
        selected = np.logical_and(times &gt;= cur, times &lt;= nxt)
        sel_x, sel_y = x[selected], y[selected]

        # add start positions and end positions to array
        start_pos[idx] = sel_x[0], sel_y[0]
        end_pos[idx] = sel_x[-1], sel_y[-1]

    #calculate distances
    distances = np.linalg.norm(end_pos - start_pos, axis=1)

    # return_start_end_pos
    out = (distances,)
    if return_start_end_pos:
        out += (start_pos, end_pos)

    # make continuous if necessary
    if not from_discrete:
        out = tuple(discrete_to_continuous(times, seg_times, i)[1] for i in out)
    return out if return_start_end_pos else out[0]


def sfreq_to_times(gaze_array, sfreq, start_time=0):
    &#34;&#34;&#34;Creates a times array from the sampling frequency (in Hertz).
    
    Parameters
    ----------
    gaze_array : array
        The gaze array (is required to infer the number of samples).
    sfreq : float
        The sampling frequency in Hz.
    start_time : float
        The time (in seconds) at which the first sample will start.
        Default = 0.
   
    Returns
    -------
    times : array of float
        A 1D-array representing the sampling times of the recording.
        &#34;&#34;&#34;
    return np.arange(0, len(gaze_array) / sfreq, 1. / sfreq) + start_time


def coords_to_degree(x, viewing_dist, screen_max, screen_min=None):
    &#34;&#34;&#34;Converts gaze data expressed in any flat spatial coordinates 
    (e.g. centimetres, inch, digital coordinate frames) to degrees.
    Assumes that the default gaze location is at the center of the
    screen.
    
    Parameters
    ----------
    x : array of float
        The gaze array to transform. Can be either a 1D or 2D array.
        If a 2-D array, the first dimension must correspond to the gaze 
        dimensions (e.g. x, y) and the second to the time dimension.
    viewing_dist : float
        The distance between the eye and the screen, measured in the 
        same unit as `screen_max` and `screen_min`.
    screen_max : float, tuple/list of float
        The maximum screen coordinates measured in the same unit as 
        `viewing_dist` and `screen_min`. If `x` is a 2D array, 
        `screen_max` must be an iterable of the same length as `x`. 
    screen_min : float, tuple/list of float
        The minimum screen coordinates measured in the same unit as 
        `viewing_dist` and `screen_min`. If `x` is a 2D array, 
        `screen_min` must be an iterable of the same length as `x`. 
        
    Returns
    -------
    x_converted : array of float
        The gaze array converted to degrees.
    &#34;&#34;&#34;
    # set default for screen min
    x = np.array(x)
    if screen_min == None:
        screen_min = np.zeros_like(screen_max)
        
    # check arguments shapes
    msg_1 = &#34;If x has more than 1 dimension, screen parameters&#34; \
    &#34; must be iterable objects with the same length as x.&#34;
    msg_2 = &#34;Multiple screen parameter dimensions &#34; \
    &#34;were passed for only one gaze series x.&#34;
    lengthy = all([hasattr(screen_max, &#39;__len__&#39;),
                   hasattr(screen_min, &#39;__len__&#39;)])
    if x.ndim &gt; 1:
        if not lengthy:
            raise ValueError(msg_1)
        else:
            if not (len(x) == len(screen_max) == len(screen_min)):
                raise ValueError(msg_1) 
    else:
        if lengthy and not (1 == len(screen_max) == len(screen_min)):
            raise ValueError(msg_2)
    
    # convert the x array to degree using the arctan
    coord_range = np.array(screen_max) - np.array(screen_min)
    coord_range = coord_range[..., np.newaxis]
    x = x - coord_range / 2.  # 0 should be at the center
    x = np.degrees(np.arctan2(x, viewing_dist))
    return x


def pixel_to_degree(x, viewing_dist, screen_size, screen_res):
    &#34;&#34;&#34;Converts gaze data expressed as pixels to degrees. Assumes 
    that the default gaze location is at the center of the screen.
    
    Parameters
    ----------
    x : array of float
        The gaze array to transform. Can be either a 1D or 2D array.
        If a 2-D array, the first dimension must correspond to the gaze 
        dimensions (e.g. x, y) and the second to the time dimension.
    viewing_dist : float
        The distance between the eye and the screen, measured in the 
        same unit as `screen_size` (e.g. inch or cm).
    screen_size : float, tuple/list of float
        The screen size measured in the same unit as `screen_res` (e.g. 
        inch or cm). If `x` is a 2D array, `screen_size` must be a
        list/array of the same length as `x`
    screen_res : float, tuple/list of float
        The screen resolution measured as a total of `screen_size` 
        (e.g. total number of pixels over one axis). If `x` is a 
        2D array, `screen_res` must be a list/array of the same 
        length as `x`.
        
    Returns
    -------
    x_converted : array of float
        The gaze array converted to degrees.
    &#34;&#34;&#34;
    # check arguments shapes
    msg_1 = &#34;If x has more than 1 dimension, screen_res&#34; \
    &#34; must be an iterable object with the same length as x.&#34;
    msg_2 = &#34;Multiple screen_res dimensions &#34; \
    &#34;were passed for only one gaze series x.&#34;
    x = np.array(x)
    lengthy = hasattr(screen_res, &#39;__len__&#39;)
    if x.ndim &gt; 1:
        if (not lengthy) or (lengthy and len(x) != len(screen_res)):
            raise ValueError(msg_1)
    else:
        if lengthy and len(screen_res) != 1:
            raise ValueError(msg_2)

    # convert from pixels to spatial unit
    x /= np.array(screen_res)[..., np.newaxis]
    x *= np.array(screen_size)[..., np.newaxis]
    
    # convert the spatial coordinates to degree
    return coords_to_degree(x, viewing_dist, screen_size)


def _get_time(x, time, warn_sfreq=False):
    &#34;&#34;&#34;Process times argument to sfreq/times array&#34;&#34;&#34;
    # process time argument
    if hasattr(time, &#39;__iter__&#39;):
        # create sfreq from times array
        times = np.array(time)
        if warn_sfreq and (np.std(times[1:] - times[:-1]) &gt; 1e-5):
            warnings.warn(WARN_SFREQ)
        sfreq = 1. / np.mean(times[1:] - times[:-1]) 
    else:
        # create times array from sfreq
        sfreq = time
        times = sfreq_to_times(x, sfreq)
    return times, sfreq</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="cateyes.utils.sample_data_path"><code class="name flex">
<span>def <span class="ident">sample_data_path</span></span>(<span>name)</span>
</code></dt>
<dd>
<div class="desc"><p>return the static path to a CatEyes sample dataset.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>The example file to load. Possible names are: 'example_data',
'example_events' and 'test_data_full'.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>data_path</code></strong> :&ensp;<code>str</code></dt>
<dd>The absolute path leading to the respective .csv file on your
machine.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sample_data_path(name):
    &#34;&#34;&#34;return the static path to a CatEyes sample dataset.
    
    Parameters
    ----------
    name : str
        The example file to load. Possible names are: &#39;example_data&#39;,
        &#39;example_events&#39; and &#39;test_data_full&#39;.
   
    Returns
    -------
    data_path : str
        The absolute path leading to the respective .csv file on your 
        machine.
        &#34;&#34;&#34;
    import os.path as op
    data_dir = op.join(op.dirname(__file__), &#34;data&#34;)
    data_path = op.join(data_dir, name + &#34;.csv&#34;)
    return op.abspath(data_path)</code></pre>
</details>
</dd>
<dt id="cateyes.utils.discrete_to_continuous"><code class="name flex">
<span>def <span class="ident">discrete_to_continuous</span></span>(<span>times, discrete_times, discrete_values)</span>
</code></dt>
<dd>
<div class="desc"><p>Matches an array of discrete events to a continuous time series.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>times</code></strong> :&ensp;<code>array</code> of <code>(float, int)</code></dt>
<dd>A 1D-array representing the sampling times of the continuous
eyetracking recording.</dd>
<dt><strong><code>discrete_times</code></strong> :&ensp;<code>array</code> of <code>(float, int)</code></dt>
<dd>A 1D-array representing discrete timepoints at which a specific
event occurs. Is used to map <code>discrete_values</code> onto <code>times</code>.</dd>
<dt><strong><code>discrete_values</code></strong> :&ensp;<code>array</code></dt>
<dd>A 1D-array containing the event description or values
corresponding to <code>discrete_times</code>. Must be the same length as
<code>discrete_times</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>indices</code></strong> :&ensp;<code>array</code> of <code>int</code></dt>
<dd>Array of length len(times) corresponding to the event index
of the discrete events mapped onto the sampling times.</dd>
<dt><strong><code>values</code></strong> :&ensp;<code>array</code></dt>
<dd>Array of length len(times) corresponding to the event values
or descriptions of the discrete events.</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; times = np.array([0., 0.1, 0.2])
&gt;&gt;&gt; dis_times, dis_values = [0.1], [&quot;Saccade&quot;]
&gt;&gt;&gt; discrete_to_continuous(times, dis_times, dis_values)
array([0., 1., 1.]), array([None, 'Saccade', 'Saccade'])
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def discrete_to_continuous(times, discrete_times, discrete_values):
    &#34;&#34;&#34;Matches an array of discrete events to a continuous time series.
    
    Parameters
    ----------
    times : array of (float, int)
        A 1D-array representing the sampling times of the continuous 
        eyetracking recording.
    discrete_times : array of (float, int)
        A 1D-array representing discrete timepoints at which a specific
        event occurs. Is used to map `discrete_values` onto `times`.
    discrete_values : array
        A 1D-array containing the event description or values 
        corresponding to `discrete_times`. Must be the same length as 
        `discrete_times`.
        
    Returns
    -------
    indices : array of int
        Array of length len(times) corresponding to the event index 
        of the discrete events mapped onto the sampling times.
    values : array
        Array of length len(times) corresponding to the event values
        or descriptions of the discrete events.
        
    Example
    --------
    &gt;&gt;&gt; times = np.array([0., 0.1, 0.2])
    &gt;&gt;&gt; dis_times, dis_values = [0.1], [&#34;Saccade&#34;]
    &gt;&gt;&gt; discrete_to_continuous(times, dis_times, dis_values)
    array([0., 1., 1.]), array([None, &#39;Saccade&#39;, &#39;Saccade&#39;])
    &#34;&#34;&#34;
    # check to prevent passing continuous array
    if len(discrete_times) == len(times):
        warnings.warn(WARN_CONT)
    #TODO: Items will be dropped if 2 discrete events fall on one sample.
    # how to deal with this?
    
    # sort the discrete events by time
    time_val_sorted = sorted(zip(discrete_times, discrete_values),
                            key= lambda x:x[0])
    
    # fill the time series with indices and values
    indices = np.zeros(len(times))
    shape, dtype = [(x.shape, x.dtype) for x in [np.array(discrete_values)]][0]
    values = np.full((len(times),) + shape[1:], None).astype(dtype)
    for idx, (dis_time, dis_val) in enumerate(time_val_sorted):
        selected = times &gt;= dis_time
        indices[selected] = idx + 1
        values[selected] = dis_val
        #for i in np.where(selected)[0]:  # this allows multidim arrays to pass
        #    values[i] = dis_val
        
    return indices, values</code></pre>
</details>
</dd>
<dt id="cateyes.utils.continuous_to_discrete"><code class="name flex">
<span>def <span class="ident">continuous_to_discrete</span></span>(<span>times, indices, values)</span>
</code></dt>
<dd>
<div class="desc"><p>Matches an array of discrete events to a continuous time series.
Reverse function of <code><a title="cateyes.utils.discrete_to_continuous" href="#cateyes.utils.discrete_to_continuous">discrete_to_continuous()</a></code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>times</code></strong> :&ensp;<code>array</code> of <code>(float, int)</code></dt>
<dd>A 1D-array representing the sampling times of the continuous
eyetracking recording.</dd>
<dt><strong><code>indices</code></strong> :&ensp;<code>array</code> of <code>int</code></dt>
<dd>Array of length len(times) corresponding to the event index
of the discrete events mapped onto the sampling times.</dd>
<dt><strong><code>values</code></strong> :&ensp;<code>array</code></dt>
<dd>Array of length len(times) corresponding to the event values
or descriptions of the discrete events.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>discrete_times</code></strong> :&ensp;<code>array</code> of <code>(float, int)</code></dt>
<dd>A 1D-array representing discrete timepoints at which a specific
event occurs.</dd>
<dt><strong><code>discrete_values</code></strong> :&ensp;<code>array</code></dt>
<dd>A 1D-array containing the event description or values
corresponding to <code>discrete_times</code>. Is the same length as
<code>discrete_times</code>.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def continuous_to_discrete(times, indices, values):
    &#34;&#34;&#34;Matches an array of discrete events to a continuous time series.
    Reverse function of `discrete_to_continuous`.
    
    Parameters
    ----------
    times : array of (float, int)
        A 1D-array representing the sampling times of the continuous 
        eyetracking recording.
    indices : array of int
        Array of length len(times) corresponding to the event index 
        of the discrete events mapped onto the sampling times.
    values : array
        Array of length len(times) corresponding to the event values
        or descriptions of the discrete events.
   
    Returns
    -------
    discrete_times : array of (float, int)
        A 1D-array representing discrete timepoints at which a specific
        event occurs.
    discrete_values : array
        A 1D-array containing the event description or values 
        corresponding to `discrete_times`. Is the same length as 
        `discrete_times`.
    &#34;&#34;&#34;
    # check to prevent passing discrete array
    if any([len(times) != i for i in (len(indices), len(values))]):
        raise ValueError(&#34;Indices and values must have the &#34; \
                         &#34;same length as the times array.&#34;)
    
    # fill the discrete lists with events
    discrete_times = []
    discrete_values = []
    cur_idx = np.min(indices) - 1
    for time, idx, val in zip(times, indices, values):
        if idx &gt; cur_idx:
            discrete_times.append(time)
            discrete_values.append(val)
        cur_idx = idx
    
    return discrete_times, discrete_values</code></pre>
</details>
</dd>
<dt id="cateyes.utils.get_segment_distance"><code class="name flex">
<span>def <span class="ident">get_segment_distance</span></span>(<span>x, y, times, segments, from_discrete=False, return_start_end_pos=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the movement distance from start to end of a segment.
This function can be used to calculate Saccade distance.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>array</code> of <code>float</code></dt>
<dd>A 1D-array representing the x-axis of your gaze data.</dd>
<dt><strong><code>y</code></strong> :&ensp;<code>array</code> of <code>float</code></dt>
<dd>A 1D-array representing the y-axis of your gaze data.</dd>
<dt><strong><code>times</code></strong> :&ensp;<code>array</code> of <code>(float, int)</code></dt>
<dd>A 1D-array representing the sampling times of the continuous
eyetracking recording.</dd>
<dt><strong><code>segments</code></strong> :&ensp;<code>array</code> of <code>(int, float)</code></dt>
<dd>Either the event indices (continuous format) or the event
times (discrete format), indicating the start of a new segment.</dd>
<dt><strong><code>from_discrete</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, assumes that <code>segments</code> is a discrete array and will
also return a discrete array. Else, will treat <code>segments</code> as
continuous array and return a continuous array. Default=False.</dd>
<dt><strong><code>return_start_end_pos</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, additionally return the initial and final position of
the gaze array during each segment. Default=False.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>distances</code></strong> :&ensp;<code>array</code> of <code>float</code></dt>
<dd>Array of length len(times) corresponding to the distance
between the first and the last sample in a segment.</dd>
<dt><strong><code>start_pos</code></strong> :&ensp;<code>array</code> of <code>float</code></dt>
<dd>A 2D array of shape [n_events, 2] (discrete) or
[n_samples, 2] (continuous) containing the initial gaze
positions for each segment. The second dimension of the
array corresponds to the x and y axis (in that order).
Only returned if <code>return_start_end_pos=True</code>.</dd>
<dt><strong><code>end_pos</code></strong> :&ensp;<code>array</code> of <code>float</code></dt>
<dd>A 2D array of shape [n_events, 2] (discrete) or
[n_samples, 2] (continuous) containing the final gaze
positions for each segment. The second dimension of the
array corresponds to the x and y axis (in that order).
Only returned if <code>return_start_end_pos=True</code>.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_segment_distance(x, y, times, segments, from_discrete=False,
                        return_start_end_pos=False):
    &#34;&#34;&#34;Calculate the movement distance from start to end of a segment.
    This function can be used to calculate Saccade distance.
    
    Parameters
    ----------
    x : array of float
        A 1D-array representing the x-axis of your gaze data.
    y : array of float
        A 1D-array representing the y-axis of your gaze data.
    times : array of (float, int)
        A 1D-array representing the sampling times of the continuous 
        eyetracking recording.
    segments : array of (int, float)
        Either the event indices (continuous format) or the event 
        times (discrete format), indicating the start of a new segment.
    from_discrete : bool
        If True, assumes that `segments` is a discrete array and will
        also return a discrete array. Else, will treat `segments` as
        continuous array and return a continuous array. Default=False.
    return_start_end_pos : bool
        If True, additionally return the initial and final position of
        the gaze array during each segment. Default=False.
        
        
    Returns
    -------
    distances : array of float
        Array of length len(times) corresponding to the distance
        between the first and the last sample in a segment.
    start_pos : array of float
        A 2D array of shape [n_events, 2] (discrete) or 
        [n_samples, 2] (continuous) containing the initial gaze 
        positions for each segment. The second dimension of the 
        array corresponds to the x and y axis (in that order).
        Only returned if `return_start_end_pos=True`.
    end_pos : array of float
        A 2D array of shape [n_events, 2] (discrete) or 
        [n_samples, 2] (continuous) containing the final gaze 
        positions for each segment. The second dimension of the 
        array corresponds to the x and y axis (in that order).
        Only returned if `return_start_end_pos=True`.
    &#34;&#34;&#34;
    # check if continuous segments match length
    msg = &#34;For continuous segments, len(segments) must be equal to &#34; \
    &#34;len(times). If you are using a discrete segment array, please &#34; \
    &#34;pass `discrete=True` as an argument&#34;
    if not from_discrete:
        if len(segments) != len(times):
            raise ValueError(msg)

        # make discrete if continuous
        segments, _ = continuous_to_discrete(times, segments, x)

    # sort the discrete events by time
    seg_times = sorted(segments)
    
    # loop over segments to find start and end positions
    start_pos, end_pos = np.zeros([2, len(seg_times), 2])  # 2 2D arrays
    nxt_seg_times = np.concatenate([seg_times[1:], [np.inf]])
    for idx, (cur, nxt) in enumerate(zip(seg_times, nxt_seg_times)):

        # select the segment in question
        selected = np.logical_and(times &gt;= cur, times &lt;= nxt)
        sel_x, sel_y = x[selected], y[selected]

        # add start positions and end positions to array
        start_pos[idx] = sel_x[0], sel_y[0]
        end_pos[idx] = sel_x[-1], sel_y[-1]

    #calculate distances
    distances = np.linalg.norm(end_pos - start_pos, axis=1)

    # return_start_end_pos
    out = (distances,)
    if return_start_end_pos:
        out += (start_pos, end_pos)

    # make continuous if necessary
    if not from_discrete:
        out = tuple(discrete_to_continuous(times, seg_times, i)[1] for i in out)
    return out if return_start_end_pos else out[0]</code></pre>
</details>
</dd>
<dt id="cateyes.utils.sfreq_to_times"><code class="name flex">
<span>def <span class="ident">sfreq_to_times</span></span>(<span>gaze_array, sfreq, start_time=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Creates a times array from the sampling frequency (in Hertz).</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>gaze_array</code></strong> :&ensp;<code>array</code></dt>
<dd>The gaze array (is required to infer the number of samples).</dd>
<dt><strong><code>sfreq</code></strong> :&ensp;<code>float</code></dt>
<dd>The sampling frequency in Hz.</dd>
<dt><strong><code>start_time</code></strong> :&ensp;<code>float</code></dt>
<dd>The time (in seconds) at which the first sample will start.
Default = 0.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>times</code></strong> :&ensp;<code>array</code> of <code>float</code></dt>
<dd>A 1D-array representing the sampling times of the recording.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sfreq_to_times(gaze_array, sfreq, start_time=0):
    &#34;&#34;&#34;Creates a times array from the sampling frequency (in Hertz).
    
    Parameters
    ----------
    gaze_array : array
        The gaze array (is required to infer the number of samples).
    sfreq : float
        The sampling frequency in Hz.
    start_time : float
        The time (in seconds) at which the first sample will start.
        Default = 0.
   
    Returns
    -------
    times : array of float
        A 1D-array representing the sampling times of the recording.
        &#34;&#34;&#34;
    return np.arange(0, len(gaze_array) / sfreq, 1. / sfreq) + start_time</code></pre>
</details>
</dd>
<dt id="cateyes.utils.coords_to_degree"><code class="name flex">
<span>def <span class="ident">coords_to_degree</span></span>(<span>x, viewing_dist, screen_max, screen_min=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Converts gaze data expressed in any flat spatial coordinates
(e.g. centimetres, inch, digital coordinate frames) to degrees.
Assumes that the default gaze location is at the center of the
screen.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>array</code> of <code>float</code></dt>
<dd>The gaze array to transform. Can be either a 1D or 2D array.
If a 2-D array, the first dimension must correspond to the gaze
dimensions (e.g. x, y) and the second to the time dimension.</dd>
<dt><strong><code>viewing_dist</code></strong> :&ensp;<code>float</code></dt>
<dd>The distance between the eye and the screen, measured in the
same unit as <code>screen_max</code> and <code>screen_min</code>.</dd>
<dt><strong><code>screen_max</code></strong> :&ensp;<code>float, tuple/list</code> of <code>float</code></dt>
<dd>The maximum screen coordinates measured in the same unit as
<code>viewing_dist</code> and <code>screen_min</code>. If <code>x</code> is a 2D array,
<code>screen_max</code> must be an iterable of the same length as <code>x</code>.</dd>
<dt><strong><code>screen_min</code></strong> :&ensp;<code>float, tuple/list</code> of <code>float</code></dt>
<dd>The minimum screen coordinates measured in the same unit as
<code>viewing_dist</code> and <code>screen_min</code>. If <code>x</code> is a 2D array,
<code>screen_min</code> must be an iterable of the same length as <code>x</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>x_converted</code></strong> :&ensp;<code>array</code> of <code>float</code></dt>
<dd>The gaze array converted to degrees.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def coords_to_degree(x, viewing_dist, screen_max, screen_min=None):
    &#34;&#34;&#34;Converts gaze data expressed in any flat spatial coordinates 
    (e.g. centimetres, inch, digital coordinate frames) to degrees.
    Assumes that the default gaze location is at the center of the
    screen.
    
    Parameters
    ----------
    x : array of float
        The gaze array to transform. Can be either a 1D or 2D array.
        If a 2-D array, the first dimension must correspond to the gaze 
        dimensions (e.g. x, y) and the second to the time dimension.
    viewing_dist : float
        The distance between the eye and the screen, measured in the 
        same unit as `screen_max` and `screen_min`.
    screen_max : float, tuple/list of float
        The maximum screen coordinates measured in the same unit as 
        `viewing_dist` and `screen_min`. If `x` is a 2D array, 
        `screen_max` must be an iterable of the same length as `x`. 
    screen_min : float, tuple/list of float
        The minimum screen coordinates measured in the same unit as 
        `viewing_dist` and `screen_min`. If `x` is a 2D array, 
        `screen_min` must be an iterable of the same length as `x`. 
        
    Returns
    -------
    x_converted : array of float
        The gaze array converted to degrees.
    &#34;&#34;&#34;
    # set default for screen min
    x = np.array(x)
    if screen_min == None:
        screen_min = np.zeros_like(screen_max)
        
    # check arguments shapes
    msg_1 = &#34;If x has more than 1 dimension, screen parameters&#34; \
    &#34; must be iterable objects with the same length as x.&#34;
    msg_2 = &#34;Multiple screen parameter dimensions &#34; \
    &#34;were passed for only one gaze series x.&#34;
    lengthy = all([hasattr(screen_max, &#39;__len__&#39;),
                   hasattr(screen_min, &#39;__len__&#39;)])
    if x.ndim &gt; 1:
        if not lengthy:
            raise ValueError(msg_1)
        else:
            if not (len(x) == len(screen_max) == len(screen_min)):
                raise ValueError(msg_1) 
    else:
        if lengthy and not (1 == len(screen_max) == len(screen_min)):
            raise ValueError(msg_2)
    
    # convert the x array to degree using the arctan
    coord_range = np.array(screen_max) - np.array(screen_min)
    coord_range = coord_range[..., np.newaxis]
    x = x - coord_range / 2.  # 0 should be at the center
    x = np.degrees(np.arctan2(x, viewing_dist))
    return x</code></pre>
</details>
</dd>
<dt id="cateyes.utils.pixel_to_degree"><code class="name flex">
<span>def <span class="ident">pixel_to_degree</span></span>(<span>x, viewing_dist, screen_size, screen_res)</span>
</code></dt>
<dd>
<div class="desc"><p>Converts gaze data expressed as pixels to degrees. Assumes
that the default gaze location is at the center of the screen.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>array</code> of <code>float</code></dt>
<dd>The gaze array to transform. Can be either a 1D or 2D array.
If a 2-D array, the first dimension must correspond to the gaze
dimensions (e.g. x, y) and the second to the time dimension.</dd>
<dt><strong><code>viewing_dist</code></strong> :&ensp;<code>float</code></dt>
<dd>The distance between the eye and the screen, measured in the
same unit as <code>screen_size</code> (e.g. inch or cm).</dd>
<dt><strong><code>screen_size</code></strong> :&ensp;<code>float, tuple/list</code> of <code>float</code></dt>
<dd>The screen size measured in the same unit as <code>screen_res</code> (e.g.
inch or cm). If <code>x</code> is a 2D array, <code>screen_size</code> must be a
list/array of the same length as <code>x</code></dd>
<dt><strong><code>screen_res</code></strong> :&ensp;<code>float, tuple/list</code> of <code>float</code></dt>
<dd>The screen resolution measured as a total of <code>screen_size</code>
(e.g. total number of pixels over one axis). If <code>x</code> is a
2D array, <code>screen_res</code> must be a list/array of the same
length as <code>x</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>x_converted</code></strong> :&ensp;<code>array</code> of <code>float</code></dt>
<dd>The gaze array converted to degrees.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pixel_to_degree(x, viewing_dist, screen_size, screen_res):
    &#34;&#34;&#34;Converts gaze data expressed as pixels to degrees. Assumes 
    that the default gaze location is at the center of the screen.
    
    Parameters
    ----------
    x : array of float
        The gaze array to transform. Can be either a 1D or 2D array.
        If a 2-D array, the first dimension must correspond to the gaze 
        dimensions (e.g. x, y) and the second to the time dimension.
    viewing_dist : float
        The distance between the eye and the screen, measured in the 
        same unit as `screen_size` (e.g. inch or cm).
    screen_size : float, tuple/list of float
        The screen size measured in the same unit as `screen_res` (e.g. 
        inch or cm). If `x` is a 2D array, `screen_size` must be a
        list/array of the same length as `x`
    screen_res : float, tuple/list of float
        The screen resolution measured as a total of `screen_size` 
        (e.g. total number of pixels over one axis). If `x` is a 
        2D array, `screen_res` must be a list/array of the same 
        length as `x`.
        
    Returns
    -------
    x_converted : array of float
        The gaze array converted to degrees.
    &#34;&#34;&#34;
    # check arguments shapes
    msg_1 = &#34;If x has more than 1 dimension, screen_res&#34; \
    &#34; must be an iterable object with the same length as x.&#34;
    msg_2 = &#34;Multiple screen_res dimensions &#34; \
    &#34;were passed for only one gaze series x.&#34;
    x = np.array(x)
    lengthy = hasattr(screen_res, &#39;__len__&#39;)
    if x.ndim &gt; 1:
        if (not lengthy) or (lengthy and len(x) != len(screen_res)):
            raise ValueError(msg_1)
    else:
        if lengthy and len(screen_res) != 1:
            raise ValueError(msg_2)

    # convert from pixels to spatial unit
    x /= np.array(screen_res)[..., np.newaxis]
    x *= np.array(screen_size)[..., np.newaxis]
    
    # convert the spatial coordinates to degree
    return coords_to_degree(x, viewing_dist, screen_size)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="cateyes" href="index.html">cateyes</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="cateyes.utils.sample_data_path" href="#cateyes.utils.sample_data_path">sample_data_path</a></code></li>
<li><code><a title="cateyes.utils.discrete_to_continuous" href="#cateyes.utils.discrete_to_continuous">discrete_to_continuous</a></code></li>
<li><code><a title="cateyes.utils.continuous_to_discrete" href="#cateyes.utils.continuous_to_discrete">continuous_to_discrete</a></code></li>
<li><code><a title="cateyes.utils.get_segment_distance" href="#cateyes.utils.get_segment_distance">get_segment_distance</a></code></li>
<li><code><a title="cateyes.utils.sfreq_to_times" href="#cateyes.utils.sfreq_to_times">sfreq_to_times</a></code></li>
<li><code><a title="cateyes.utils.coords_to_degree" href="#cateyes.utils.coords_to_degree">coords_to_degree</a></code></li>
<li><code><a title="cateyes.utils.pixel_to_degree" href="#cateyes.utils.pixel_to_degree">pixel_to_degree</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.0</a>.</p>
</footer>
</body>
</html>