<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>cateye.utils API documentation</title>
<meta name="description" content="cateye.utils provides utility functions to convert and handle data." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>cateye.utils</code></h1>
</header>
<section id="section-intro">
<p>cateye.utils provides utility functions to convert and handle data.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># -*- coding: utf-8 -*-
# (c) Dirk GÃ¼tlin, 2021. &lt;dirk.guetlin@gmail.com&gt;
#
# License: BSD-3-Clause

&#34;&#34;&#34;
cateye.utils provides utility functions to convert and handle data.
&#34;&#34;&#34;

import numpy as np


def sample_data_path(name):
    &#34;&#34;&#34;return the static path to a CatEye sample dataset.
    
    Parameters
    ----------
    name : str
        The example file to load. Possible names are: &#39;example_data&#39;,
        &#39;example_events&#39; and &#39;test_data_full&#39;.
   
    Returns
    -------
    data_path : str
        The absolute path leading to the respective .csv file on your 
        machine.
        &#34;&#34;&#34;
    import os.path as op
    data_dir = op.join(op.dirname(__file__), &#34;data&#34;)
    data_path = op.join(data_dir, name + &#34;.csv&#34;)
    return op.abspath(data_path)


def discrete_to_continuous(times, discrete_times, discrete_values):
    &#34;&#34;&#34;Matches an array of discrete events to a continuous time series.
    
    Parameters
    ----------
    times : array of (float, int)
        A 1D-array representing the sampling times of the continuous 
        eyetracking recording.
    discrete_times : array of (float, int)
        A 1D-array representing discrete timepoints at which a specific
        event occurs. Is used to map `discrete_values` onto `times`.
    discrete_values : array
        A 1D-array containing the event description or values 
        corresponding to `discrete_times`. Must be the same length as 
        `discrete_times`.
        
    Returns
    -------
    indices : array of int
        Array of length len(times) corresponding to the event index 
        of the discrete events mapped onto the sampling times.
    values : array
        Array of length len(times) corresponding to the event values
        or descriptions of the discrete events.
        
    Example
    --------
    &gt;&gt;&gt; times = np.array([0., 0.1, 0.2])
    &gt;&gt;&gt; dis_times, dis_values = [0.1], [&#34;Saccade&#34;]
    &gt;&gt;&gt; discrete_to_continuous(times, dis_times, dis_values)
    array([0., 1., 1.]), array([None, &#39;Saccade&#39;, &#39;Saccade&#39;])
    &#34;&#34;&#34;
    
    # sort the discrete events by time
    time_val_sorted = sorted(zip(discrete_times, discrete_values))
    
    # fill the time series with indices and values
    indices = np.zeros(len(times))
    values = np.empty(len(times), dtype=object)
    for idx, (dis_time, dis_val) in enumerate(time_val_sorted):
        selected = [times &gt;= dis_time]
        indices[selected] = idx + 1
        values[selected] = dis_val
        
    return indices, values


def continuous_to_discrete(times, indices, values):
    &#34;&#34;&#34;Matches an array of discrete events to a continuous time series.
    Reverse function of `discrete_to_continuous`.
    
    Parameters
    ----------
    times : array of (float, int)
        A 1D-array representing the sampling times of the continuous 
        eyetracking recording.
    indices : array of int
        Array of length len(times) corresponding to the event index 
        of the discrete events mapped onto the sampling times.
    values : array
        Array of length len(times) corresponding to the event values
        or descriptions of the discrete events.
   
    Returns
    -------
    discrete_times : array of (float, int)
        A 1D-array representing discrete timepoints at which a specific
        event occurs.
    discrete_values : array
        A 1D-array containing the event description or values 
        corresponding to `discrete_times`. Is the same length as 
        `discrete_times`.
    &#34;&#34;&#34;
    
    # fill the discrete lists with events
    discrete_times = []
    discrete_values = []
    cur_idx = np.min(indices) - 1
    for time, idx, val in zip(times, indices, values):
        if idx &gt; cur_idx:
            discrete_times.append(time)
            discrete_values.append(val)
        cur_idx = idx
    
    return discrete_times, discrete_values


def sfreq_to_times(gaze_array, sfreq, start_time=0):
    &#34;&#34;&#34;Creates a times array from the sampling frequency (in Hertz).
    
    Parameters
    ----------
    gaze_array : array
        The gaze array (is required to infer the number of samples).
    sfreq : float
        The sampling frequency in Hz.
    start_time : float
        The time (in seconds) at which the first sample will start.
        Default = 0.
   
    Returns
    -------
    times : array of float
        A 1D-array representing the sampling times of the recording.
        &#34;&#34;&#34;
    return np.arange(0, len(gaze_array) / sfreq, 1. / sfreq) + start_time


def coords_to_degree(x, viewing_dist, screen_max, screen_min=None):
    &#34;&#34;&#34;Converts gaze data expressed in any flat spatial coordinates 
    (e.g. centimetres, inch, digital coordinate frames) to degrees.
    Assumes that the default gaze location is at the center of the
    screen.
    
    Parameters
    ----------
    x : array of float
        The gaze array to transform. Can be either a 1D or 2D array.
        If a 2-D array, the first dimension must correspond to the gaze 
        dimensions (e.g. x, y) and the second to the time dimension.
    viewing_dist : float
        The distance between the eye and the screen, measured in the 
        same unit as `screen_max` and `screen_min`.
    screen_max : float, tuple/list of float
        The maximum screen coordinates measured in the same unit as 
        `viewing_dist` and `screen_min`. If `x` is a 2D array, `
        screen_max` must be an iterable of the same length as `x`. 
    screen_min : float, tuple/list of float
        The minimum screen coordinates measured in the same unit as 
        `viewing_dist` and `screen_min`. If `x` is a 2D array, `
        screen_min` must be an iterable of the same length as `x`. 
        
    Returns
    -------
    x_converted : array of float
        The gaze array converted to degrees.
    &#34;&#34;&#34;
    # set default for screen min
    x = np.array(x)
    if screen_min == None:
        screen_min = np.zeros_like(screen_max)
        
    # check arguments shapes
    msg_1 = &#34;If x has more than 1 dimension, screen parameters&#34; \
    &#34; must be iterable objects with the same length as x.&#34;
    msg_2 = &#34;Multiple screen parameter dimensions &#34; \
    &#34;were passed for only one gaze series x.&#34;
    lengthy = all([hasattr(screen_max, &#39;__len__&#39;),
                   hasattr(screen_min, &#39;__len__&#39;)])
    if x.ndim &gt; 1:
        if not lengthy:
            raise ValueError(msg_1)
        else:
            if not (len(x) == len(screen_max) == len(screen_min)):
                raise ValueError(msg_1) 
    else:
        if lengthy and not (1 == len(screen_max) == len(screen_min)):
            raise ValueError(msg_2)
    
    # convert the x array to degree using the arctan
    coord_range = np.array(screen_max) - np.array(screen_min)
    coord_range = coord_range.reshape(-1, 1)
    x = x - coord_range / 2.  # 0 should be at the center
    x = np.degrees(np.arctan2(x, viewing_dist))
    return x


def pixel_to_degree(x, viewing_dist, screen_size, screen_res):
    &#34;&#34;&#34;Converts gaze data expressed as pixels to degrees. Assumes 
    that the default gaze location is at the center of the screen.
    
    Parameters
    ----------
    x : array of float
        The gaze array to transform. Can be either a 1D or 2D array.
        If a 2-D array, the first dimension must correspond to the gaze 
        dimensions (e.g. x, y) and the second to the time dimension.
    viewing_dist : float
        The distance between the eye and the screen, measured in the 
        same unit as `screen_size`.
    screen_size : float, tuple/list of float
        The screen size measured in the same unit as `screen_res`. 
        If `x` is a 2D array, `screen_size` must be an iterable of the
        same length as `x`.
    screen_res : float, tuple/list of float
        The screen resolution measured in the same unit as `screen_size`. 
        If `x` is a 2D array, `screen_res` must be an iterable of the
        same length as `x`.
        
    Returns
    -------
    x_converted : array of float
        The gaze array converted to degrees.
    &#34;&#34;&#34;
    # check arguments shapes
    msg_1 = &#34;If x has more than 1 dimension, screen_res&#34; \
    &#34; must be an iterable object with the same length as x.&#34;
    msg_2 = &#34;Multiple screen_res dimensions &#34; \
    &#34;were passed for only one gaze series x.&#34;
    x = np.array(x)
    lengthy = hasattr(screen_res, &#39;__len__&#39;)
    if x.ndim &gt; 1:
        if (not lengthy) or (lengthy and len(x) != len(screen_res)):
            raise ValueError(msg_1)
    else:
        if lengthy and len(screen_max) != 1:
            raise ValueError(msg_2)

    # convert from pixels to spatial unit
    screen_size = np.array(screen_size).reshape(-1, 1)
    screen_res = np.array(screen_res).reshape(-1, 1)
    x = x / screen_res * screen_size
    
    # convert the spatial coordinates to degree
    return coords_to_degree(x, viewing_dist, screen_size)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="cateye.utils.continuous_to_discrete"><code class="name flex">
<span>def <span class="ident">continuous_to_discrete</span></span>(<span>times, indices, values)</span>
</code></dt>
<dd>
<div class="desc"><p>Matches an array of discrete events to a continuous time series.
Reverse function of <code><a title="cateye.utils.discrete_to_continuous" href="#cateye.utils.discrete_to_continuous">discrete_to_continuous()</a></code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>times</code></strong> :&ensp;<code>array</code> of <code>(float, int)</code></dt>
<dd>A 1D-array representing the sampling times of the continuous
eyetracking recording.</dd>
<dt><strong><code>indices</code></strong> :&ensp;<code>array</code> of <code>int</code></dt>
<dd>Array of length len(times) corresponding to the event index
of the discrete events mapped onto the sampling times.</dd>
<dt><strong><code>values</code></strong> :&ensp;<code>array</code></dt>
<dd>Array of length len(times) corresponding to the event values
or descriptions of the discrete events.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>discrete_times</code></strong> :&ensp;<code>array</code> of <code>(float, int)</code></dt>
<dd>A 1D-array representing discrete timepoints at which a specific
event occurs.</dd>
<dt><strong><code>discrete_values</code></strong> :&ensp;<code>array</code></dt>
<dd>A 1D-array containing the event description or values
corresponding to <code>discrete_times</code>. Is the same length as
<code>discrete_times</code>.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def continuous_to_discrete(times, indices, values):
    &#34;&#34;&#34;Matches an array of discrete events to a continuous time series.
    Reverse function of `discrete_to_continuous`.
    
    Parameters
    ----------
    times : array of (float, int)
        A 1D-array representing the sampling times of the continuous 
        eyetracking recording.
    indices : array of int
        Array of length len(times) corresponding to the event index 
        of the discrete events mapped onto the sampling times.
    values : array
        Array of length len(times) corresponding to the event values
        or descriptions of the discrete events.
   
    Returns
    -------
    discrete_times : array of (float, int)
        A 1D-array representing discrete timepoints at which a specific
        event occurs.
    discrete_values : array
        A 1D-array containing the event description or values 
        corresponding to `discrete_times`. Is the same length as 
        `discrete_times`.
    &#34;&#34;&#34;
    
    # fill the discrete lists with events
    discrete_times = []
    discrete_values = []
    cur_idx = np.min(indices) - 1
    for time, idx, val in zip(times, indices, values):
        if idx &gt; cur_idx:
            discrete_times.append(time)
            discrete_values.append(val)
        cur_idx = idx
    
    return discrete_times, discrete_values</code></pre>
</details>
</dd>
<dt id="cateye.utils.coords_to_degree"><code class="name flex">
<span>def <span class="ident">coords_to_degree</span></span>(<span>x, viewing_dist, screen_max, screen_min=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Converts gaze data expressed in any flat spatial coordinates
(e.g. centimetres, inch, digital coordinate frames) to degrees.
Assumes that the default gaze location is at the center of the
screen.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>array</code> of <code>float</code></dt>
<dd>The gaze array to transform. Can be either a 1D or 2D array.
If a 2-D array, the first dimension must correspond to the gaze
dimensions (e.g. x, y) and the second to the time dimension.</dd>
<dt><strong><code>viewing_dist</code></strong> :&ensp;<code>float</code></dt>
<dd>The distance between the eye and the screen, measured in the
same unit as <code>screen_max</code> and <code>screen_min</code>.</dd>
<dt><strong><code>screen_max</code></strong> :&ensp;<code>float, tuple/list</code> of <code>float</code></dt>
<dd>The maximum screen coordinates measured in the same unit as
<code>viewing_dist</code> and <code>screen_min</code>. If <code>x</code> is a 2D array, <code>screen_max&lt;code&gt; must be an iterable of the same length as &lt;/code&gt;x</code>.</dd>
<dt><strong><code>screen_min</code></strong> :&ensp;<code>float, tuple/list</code> of <code>float</code></dt>
<dd>The minimum screen coordinates measured in the same unit as
<code>viewing_dist</code> and <code>screen_min</code>. If <code>x</code> is a 2D array, <code>screen_min&lt;code&gt; must be an iterable of the same length as &lt;/code&gt;x</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>x_converted</code></strong> :&ensp;<code>array</code> of <code>float</code></dt>
<dd>The gaze array converted to degrees.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def coords_to_degree(x, viewing_dist, screen_max, screen_min=None):
    &#34;&#34;&#34;Converts gaze data expressed in any flat spatial coordinates 
    (e.g. centimetres, inch, digital coordinate frames) to degrees.
    Assumes that the default gaze location is at the center of the
    screen.
    
    Parameters
    ----------
    x : array of float
        The gaze array to transform. Can be either a 1D or 2D array.
        If a 2-D array, the first dimension must correspond to the gaze 
        dimensions (e.g. x, y) and the second to the time dimension.
    viewing_dist : float
        The distance between the eye and the screen, measured in the 
        same unit as `screen_max` and `screen_min`.
    screen_max : float, tuple/list of float
        The maximum screen coordinates measured in the same unit as 
        `viewing_dist` and `screen_min`. If `x` is a 2D array, `
        screen_max` must be an iterable of the same length as `x`. 
    screen_min : float, tuple/list of float
        The minimum screen coordinates measured in the same unit as 
        `viewing_dist` and `screen_min`. If `x` is a 2D array, `
        screen_min` must be an iterable of the same length as `x`. 
        
    Returns
    -------
    x_converted : array of float
        The gaze array converted to degrees.
    &#34;&#34;&#34;
    # set default for screen min
    x = np.array(x)
    if screen_min == None:
        screen_min = np.zeros_like(screen_max)
        
    # check arguments shapes
    msg_1 = &#34;If x has more than 1 dimension, screen parameters&#34; \
    &#34; must be iterable objects with the same length as x.&#34;
    msg_2 = &#34;Multiple screen parameter dimensions &#34; \
    &#34;were passed for only one gaze series x.&#34;
    lengthy = all([hasattr(screen_max, &#39;__len__&#39;),
                   hasattr(screen_min, &#39;__len__&#39;)])
    if x.ndim &gt; 1:
        if not lengthy:
            raise ValueError(msg_1)
        else:
            if not (len(x) == len(screen_max) == len(screen_min)):
                raise ValueError(msg_1) 
    else:
        if lengthy and not (1 == len(screen_max) == len(screen_min)):
            raise ValueError(msg_2)
    
    # convert the x array to degree using the arctan
    coord_range = np.array(screen_max) - np.array(screen_min)
    coord_range = coord_range.reshape(-1, 1)
    x = x - coord_range / 2.  # 0 should be at the center
    x = np.degrees(np.arctan2(x, viewing_dist))
    return x</code></pre>
</details>
</dd>
<dt id="cateye.utils.discrete_to_continuous"><code class="name flex">
<span>def <span class="ident">discrete_to_continuous</span></span>(<span>times, discrete_times, discrete_values)</span>
</code></dt>
<dd>
<div class="desc"><p>Matches an array of discrete events to a continuous time series.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>times</code></strong> :&ensp;<code>array</code> of <code>(float, int)</code></dt>
<dd>A 1D-array representing the sampling times of the continuous
eyetracking recording.</dd>
<dt><strong><code>discrete_times</code></strong> :&ensp;<code>array</code> of <code>(float, int)</code></dt>
<dd>A 1D-array representing discrete timepoints at which a specific
event occurs. Is used to map <code>discrete_values</code> onto <code>times</code>.</dd>
<dt><strong><code>discrete_values</code></strong> :&ensp;<code>array</code></dt>
<dd>A 1D-array containing the event description or values
corresponding to <code>discrete_times</code>. Must be the same length as
<code>discrete_times</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>indices</code></strong> :&ensp;<code>array</code> of <code>int</code></dt>
<dd>Array of length len(times) corresponding to the event index
of the discrete events mapped onto the sampling times.</dd>
<dt><strong><code>values</code></strong> :&ensp;<code>array</code></dt>
<dd>Array of length len(times) corresponding to the event values
or descriptions of the discrete events.</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; times = np.array([0., 0.1, 0.2])
&gt;&gt;&gt; dis_times, dis_values = [0.1], [&quot;Saccade&quot;]
&gt;&gt;&gt; discrete_to_continuous(times, dis_times, dis_values)
array([0., 1., 1.]), array([None, 'Saccade', 'Saccade'])
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def discrete_to_continuous(times, discrete_times, discrete_values):
    &#34;&#34;&#34;Matches an array of discrete events to a continuous time series.
    
    Parameters
    ----------
    times : array of (float, int)
        A 1D-array representing the sampling times of the continuous 
        eyetracking recording.
    discrete_times : array of (float, int)
        A 1D-array representing discrete timepoints at which a specific
        event occurs. Is used to map `discrete_values` onto `times`.
    discrete_values : array
        A 1D-array containing the event description or values 
        corresponding to `discrete_times`. Must be the same length as 
        `discrete_times`.
        
    Returns
    -------
    indices : array of int
        Array of length len(times) corresponding to the event index 
        of the discrete events mapped onto the sampling times.
    values : array
        Array of length len(times) corresponding to the event values
        or descriptions of the discrete events.
        
    Example
    --------
    &gt;&gt;&gt; times = np.array([0., 0.1, 0.2])
    &gt;&gt;&gt; dis_times, dis_values = [0.1], [&#34;Saccade&#34;]
    &gt;&gt;&gt; discrete_to_continuous(times, dis_times, dis_values)
    array([0., 1., 1.]), array([None, &#39;Saccade&#39;, &#39;Saccade&#39;])
    &#34;&#34;&#34;
    
    # sort the discrete events by time
    time_val_sorted = sorted(zip(discrete_times, discrete_values))
    
    # fill the time series with indices and values
    indices = np.zeros(len(times))
    values = np.empty(len(times), dtype=object)
    for idx, (dis_time, dis_val) in enumerate(time_val_sorted):
        selected = [times &gt;= dis_time]
        indices[selected] = idx + 1
        values[selected] = dis_val
        
    return indices, values</code></pre>
</details>
</dd>
<dt id="cateye.utils.pixel_to_degree"><code class="name flex">
<span>def <span class="ident">pixel_to_degree</span></span>(<span>x, viewing_dist, screen_size, screen_res)</span>
</code></dt>
<dd>
<div class="desc"><p>Converts gaze data expressed as pixels to degrees. Assumes
that the default gaze location is at the center of the screen.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>array</code> of <code>float</code></dt>
<dd>The gaze array to transform. Can be either a 1D or 2D array.
If a 2-D array, the first dimension must correspond to the gaze
dimensions (e.g. x, y) and the second to the time dimension.</dd>
<dt><strong><code>viewing_dist</code></strong> :&ensp;<code>float</code></dt>
<dd>The distance between the eye and the screen, measured in the
same unit as <code>screen_size</code>.</dd>
<dt><strong><code>screen_size</code></strong> :&ensp;<code>float, tuple/list</code> of <code>float</code></dt>
<dd>The screen size measured in the same unit as <code>screen_res</code>.
If <code>x</code> is a 2D array, <code>screen_size</code> must be an iterable of the
same length as <code>x</code>.</dd>
<dt><strong><code>screen_res</code></strong> :&ensp;<code>float, tuple/list</code> of <code>float</code></dt>
<dd>The screen resolution measured in the same unit as <code>screen_size</code>.
If <code>x</code> is a 2D array, <code>screen_res</code> must be an iterable of the
same length as <code>x</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>x_converted</code></strong> :&ensp;<code>array</code> of <code>float</code></dt>
<dd>The gaze array converted to degrees.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pixel_to_degree(x, viewing_dist, screen_size, screen_res):
    &#34;&#34;&#34;Converts gaze data expressed as pixels to degrees. Assumes 
    that the default gaze location is at the center of the screen.
    
    Parameters
    ----------
    x : array of float
        The gaze array to transform. Can be either a 1D or 2D array.
        If a 2-D array, the first dimension must correspond to the gaze 
        dimensions (e.g. x, y) and the second to the time dimension.
    viewing_dist : float
        The distance between the eye and the screen, measured in the 
        same unit as `screen_size`.
    screen_size : float, tuple/list of float
        The screen size measured in the same unit as `screen_res`. 
        If `x` is a 2D array, `screen_size` must be an iterable of the
        same length as `x`.
    screen_res : float, tuple/list of float
        The screen resolution measured in the same unit as `screen_size`. 
        If `x` is a 2D array, `screen_res` must be an iterable of the
        same length as `x`.
        
    Returns
    -------
    x_converted : array of float
        The gaze array converted to degrees.
    &#34;&#34;&#34;
    # check arguments shapes
    msg_1 = &#34;If x has more than 1 dimension, screen_res&#34; \
    &#34; must be an iterable object with the same length as x.&#34;
    msg_2 = &#34;Multiple screen_res dimensions &#34; \
    &#34;were passed for only one gaze series x.&#34;
    x = np.array(x)
    lengthy = hasattr(screen_res, &#39;__len__&#39;)
    if x.ndim &gt; 1:
        if (not lengthy) or (lengthy and len(x) != len(screen_res)):
            raise ValueError(msg_1)
    else:
        if lengthy and len(screen_max) != 1:
            raise ValueError(msg_2)

    # convert from pixels to spatial unit
    screen_size = np.array(screen_size).reshape(-1, 1)
    screen_res = np.array(screen_res).reshape(-1, 1)
    x = x / screen_res * screen_size
    
    # convert the spatial coordinates to degree
    return coords_to_degree(x, viewing_dist, screen_size)</code></pre>
</details>
</dd>
<dt id="cateye.utils.sample_data_path"><code class="name flex">
<span>def <span class="ident">sample_data_path</span></span>(<span>name)</span>
</code></dt>
<dd>
<div class="desc"><p>return the static path to a CatEye sample dataset.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>The example file to load. Possible names are: 'example_data',
'example_events' and 'test_data_full'.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>data_path</code></strong> :&ensp;<code>str</code></dt>
<dd>The absolute path leading to the respective .csv file on your
machine.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sample_data_path(name):
    &#34;&#34;&#34;return the static path to a CatEye sample dataset.
    
    Parameters
    ----------
    name : str
        The example file to load. Possible names are: &#39;example_data&#39;,
        &#39;example_events&#39; and &#39;test_data_full&#39;.
   
    Returns
    -------
    data_path : str
        The absolute path leading to the respective .csv file on your 
        machine.
        &#34;&#34;&#34;
    import os.path as op
    data_dir = op.join(op.dirname(__file__), &#34;data&#34;)
    data_path = op.join(data_dir, name + &#34;.csv&#34;)
    return op.abspath(data_path)</code></pre>
</details>
</dd>
<dt id="cateye.utils.sfreq_to_times"><code class="name flex">
<span>def <span class="ident">sfreq_to_times</span></span>(<span>gaze_array, sfreq, start_time=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Creates a times array from the sampling frequency (in Hertz).</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>gaze_array</code></strong> :&ensp;<code>array</code></dt>
<dd>The gaze array (is required to infer the number of samples).</dd>
<dt><strong><code>sfreq</code></strong> :&ensp;<code>float</code></dt>
<dd>The sampling frequency in Hz.</dd>
<dt><strong><code>start_time</code></strong> :&ensp;<code>float</code></dt>
<dd>The time (in seconds) at which the first sample will start.
Default = 0.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>times</code></strong> :&ensp;<code>array</code> of <code>float</code></dt>
<dd>A 1D-array representing the sampling times of the recording.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sfreq_to_times(gaze_array, sfreq, start_time=0):
    &#34;&#34;&#34;Creates a times array from the sampling frequency (in Hertz).
    
    Parameters
    ----------
    gaze_array : array
        The gaze array (is required to infer the number of samples).
    sfreq : float
        The sampling frequency in Hz.
    start_time : float
        The time (in seconds) at which the first sample will start.
        Default = 0.
   
    Returns
    -------
    times : array of float
        A 1D-array representing the sampling times of the recording.
        &#34;&#34;&#34;
    return np.arange(0, len(gaze_array) / sfreq, 1. / sfreq) + start_time</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="cateye" href="index.html">cateye</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="cateye.utils.continuous_to_discrete" href="#cateye.utils.continuous_to_discrete">continuous_to_discrete</a></code></li>
<li><code><a title="cateye.utils.coords_to_degree" href="#cateye.utils.coords_to_degree">coords_to_degree</a></code></li>
<li><code><a title="cateye.utils.discrete_to_continuous" href="#cateye.utils.discrete_to_continuous">discrete_to_continuous</a></code></li>
<li><code><a title="cateye.utils.pixel_to_degree" href="#cateye.utils.pixel_to_degree">pixel_to_degree</a></code></li>
<li><code><a title="cateye.utils.sample_data_path" href="#cateye.utils.sample_data_path">sample_data_path</a></code></li>
<li><code><a title="cateye.utils.sfreq_to_times" href="#cateye.utils.sfreq_to_times">sfreq_to_times</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>